{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVCvhTfIJJf0"
   },
   "source": [
    "# Exercise 2. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9AczlUWfwpd6",
    "outputId": "8afb04a7-26bb-4bc4-db91-040ff4ff78b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZPVKf76JJf5"
   },
   "source": [
    "In this exercise, we will be using the 20-Newsgroups dataset. This version of the dataset contains about 11k newsgroups posts from 20 different topics.\n",
    "\n",
    "We will learn how to apply the following steps:\n",
    "\n",
    "1. Import and examine data\n",
    "2. Remove initial text metadata with regex\n",
    "3. Remove numbers, punctuation, tabs and convert to lower case with gensim\n",
    "4. Stopwords and short words removal\n",
    "5. Stemming and lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pt8XPwpJJf6",
    "outputId": "8f6acd0e-43db-4bc9-e668-bfb522586ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import re\n",
    "from gensim.parsing.preprocessing import STOPWORDS, strip_tags, strip_numeric, strip_punctuation, strip_multiple_whitespaces, remove_stopwords, strip_short, stem_text\n",
    "import pickle\n",
    "import en_core_web_sm\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "iqbibgI_Apwb"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5NRuxwx9JJf8"
   },
   "source": [
    "# 1. Import and examine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "p34gaa_tJJf8",
    "outputId": "f7d1e3a0-c252-4dff-f84d-2b03e5d597f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  ...           target_names\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...  ...              rec.autos\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...  ...  comp.sys.mac.hardware\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...  ...  comp.sys.mac.hardware\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...  ...          comp.graphics\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...  ...              sci.space\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zSKKAbCIJJf8",
    "outputId": "3ceab071-47cd-429b-d37b-b58b555596b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tagret values:\n",
      "['rec.autos' 'comp.sys.mac.hardware' 'comp.graphics' 'sci.space'\n",
      " 'talk.politics.guns' 'sci.med' 'comp.sys.ibm.pc.hardware'\n",
      " 'comp.os.ms-windows.misc' 'rec.motorcycles' 'talk.religion.misc'\n",
      " 'misc.forsale' 'alt.atheism' 'sci.electronics' 'comp.windows.x'\n",
      " 'rec.sport.hockey' 'rec.sport.baseball' 'soc.religion.christian'\n",
      " 'talk.politics.mideast' 'talk.politics.misc' 'sci.crypt']\n",
      " \n",
      "Class distribution:\n",
      "rec.sport.hockey            600\n",
      "soc.religion.christian      599\n",
      "rec.motorcycles             598\n",
      "rec.sport.baseball          597\n",
      "sci.crypt                   595\n",
      "sci.med                     594\n",
      "rec.autos                   594\n",
      "comp.windows.x              593\n",
      "sci.space                   593\n",
      "comp.os.ms-windows.misc     591\n",
      "sci.electronics             591\n",
      "comp.sys.ibm.pc.hardware    590\n",
      "misc.forsale                585\n",
      "comp.graphics               584\n",
      "comp.sys.mac.hardware       578\n",
      "talk.politics.mideast       564\n",
      "talk.politics.guns          546\n",
      "alt.atheism                 480\n",
      "talk.politics.misc          465\n",
      "talk.religion.misc          377\n",
      "Name: target_names, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Examine dataset\n",
    "print('Possible tagret values:')\n",
    "print(df.target_names.unique())\n",
    "print(' ')\n",
    "print('Class distribution:')\n",
    "print(df.target_names.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCGteqesJJf9"
   },
   "source": [
    "*The classes are almost uniformly distributed.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qU-E-1ZlJJf9",
    "outputId": "e390c63e-053b-4bef-ea0c-24fe82bbeae1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The first entry in the content field\n",
    "print(df.content[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BbbUUYfPJJf-",
    "outputId": "8f62b9d1-b42a-4c12-d757-02563cfb9a1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMhzS3CRJJf-"
   },
   "source": [
    "*The data contains 11314 rows.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-CJmcBZJJf-"
   },
   "source": [
    "# 2. Remove initial text metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIMw4jPDJJf-",
    "outputId": "7fdf029c-b7f2-45b6-a4f6-216f7f47ddcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WHAT car is this!?\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary headers\n",
    "#(8768|9875|2353)\n",
    "data = [re.sub('(?m)^(From:|Article-I.D.:|Organization:|Lines:|Nntp-Posting-Host:|Distribution:|Reply-To:|X-Newsreader:|Expires:|\\s*-+).*\\n', '', sent, flags=re.I) for sent in df.content]\n",
    "data = [re.sub('(Subject:|Summary:|Keywords:)', '', sent, flags=re.I) for sent in data]\n",
    "\n",
    "#print(df.iloc[10]['content'])\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLnjdmT-JJf_"
   },
   "source": [
    "# 3. Remove numbers, punctuation, tabs and convert to lower case with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MG2zjzvJJJf_",
    "outputId": "680e5568-a70c-492e-cca8-9165ceab0691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WHAT car is this!?\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a -door sports car, looked to be from the late s/\n",
      "early s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove numbers\n",
    "data=[strip_numeric(sent) for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iBEw3QhEJJf_",
    "outputId": "742d3e44-6406-49bd-d624-01559d8cdd17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WHAT car is this \n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day  It was a  door sports car  looked to be from the late s \n",
      "early s  It was called a Bricklin  The doors were really small  In addition \n",
      "the front bumper was separate from the rest of the body  This is \n",
      "all I know  If anyone can tellme a model name  engine specs  years\n",
      "of production  where this car is made  history  or whatever info you\n",
      "have on this funky looking car  please e mail \n",
      "\n",
      "Thanks \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "data=[strip_punctuation(sent) for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hLGucgxjJJgA",
    "outputId": "2848093f-42c6-4f79-feb3-89b56eb32fac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " WHAT car is this I was wondering if anyone out there could enlighten me on this car I saw the other day It was a door sports car looked to be from the late s early s It was called a Bricklin The doors were really small In addition the front bumper was separate from the rest of the body This is all I know If anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail Thanks \n"
     ]
    }
   ],
   "source": [
    "# Remove multiple spaces\n",
    "data=[strip_multiple_whitespaces(sent) for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nRFsjDFJJgA",
    "outputId": "59b53c33-fa7d-4063-ea4a-8dc3f3c7dcc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " what car is this i was wondering if anyone out there could enlighten me on this car i saw the other day it was a door sports car looked to be from the late s early s it was called a bricklin the doors were really small in addition the front bumper was separate from the rest of the body this is all i know if anyone can tellme a model name engine specs years of production where this car is made history or whatever info you have on this funky looking car please e mail thanks \n"
     ]
    }
   ],
   "source": [
    "# Transform all data to lower-case\n",
    "data=[sent.lower() for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGSM9Y7SJJgA"
   },
   "source": [
    "# 4. Stopwords and short words removal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNJEowkTJJgA"
   },
   "source": [
    "Here we will compare the stopwords in gensim and nltk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idT5PFQRJJgA"
   },
   "source": [
    "#### Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XNIctUfAJJgB",
    "outputId": "251f37d9-cc51-4d31-8d3d-ea85408cd6c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'across', 'after', 'afterwards', 'again', 'against', 'all', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'amoungst', 'amount', 'an', 'and', 'another', 'any', 'anyhow', 'anyone', 'anything', 'anyway', 'anywhere', 'are', 'around', 'as', 'at', 'back', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'below', 'beside', 'besides', 'between', 'beyond', 'bill', 'both', 'bottom', 'but', 'by', 'call', 'can', 'cannot', 'cant', 'co', 'computer', 'con', 'could', 'couldnt', 'cry', 'de', 'describe', 'detail', 'did', 'didn', 'do', 'does', 'doesn', 'doing', 'don', 'done', 'down', 'due', 'during', 'each', 'eg', 'eight', 'either', 'eleven', 'else', 'elsewhere', 'empty', 'enough', 'etc', 'even', 'ever', 'every', 'everyone', 'everything', 'everywhere', 'except', 'few', 'fifteen', 'fify', 'fill', 'find', 'fire', 'first', 'five', 'for', 'former', 'formerly', 'forty', 'found', 'four', 'from', 'front', 'full', 'further', 'get', 'give', 'go', 'had', 'has', 'hasnt', 'have', 'he', 'hence', 'her', 'here', 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'however', 'hundred', 'i', 'ie', 'if', 'in', 'inc', 'indeed', 'interest', 'into', 'is', 'it', 'its', 'itself', 'just', 'keep', 'kg', 'km', 'last', 'latter', 'latterly', 'least', 'less', 'ltd', 'made', 'make', 'many', 'may', 'me', 'meanwhile', 'might', 'mill', 'mine', 'more', 'moreover', 'most', 'mostly', 'move', 'much', 'must', 'my', 'myself', 'name', 'namely', 'neither', 'never', 'nevertheless', 'next', 'nine', 'no', 'nobody', 'none', 'noone', 'nor', 'not', 'nothing', 'now', 'nowhere', 'of', 'off', 'often', 'on', 'once', 'one', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'part', 'per', 'perhaps', 'please', 'put', 'quite', 'rather', 're', 'really', 'regarding', 'same', 'say', 'see', 'seem', 'seemed', 'seeming', 'seems', 'serious', 'several', 'she', 'should', 'show', 'side', 'since', 'sincere', 'six', 'sixty', 'so', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhere', 'still', 'such', 'system', 'take', 'ten', 'than', 'that', 'the', 'their', 'them', 'themselves', 'then', 'thence', 'there', 'thereafter', 'thereby', 'therefore', 'therein', 'thereupon', 'these', 'they', 'thick', 'thin', 'third', 'this', 'those', 'though', 'three', 'through', 'throughout', 'thru', 'thus', 'to', 'together', 'too', 'top', 'toward', 'towards', 'twelve', 'twenty', 'two', 'un', 'under', 'unless', 'until', 'up', 'upon', 'us', 'used', 'using', 'various', 'very', 'via', 'was', 'we', 'well', 'were', 'what', 'whatever', 'when', 'whence', 'whenever', 'where', 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'whoever', 'whole', 'whom', 'whose', 'why', 'will', 'with', 'within', 'without', 'would', 'yet', 'you', 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "all_stopwords = STOPWORDS\n",
    "print(sorted(all_stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DIXFtan1JJgB"
   },
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ei1zHrFtJJgB",
    "outputId": "ce4c8d9a-74ab-4c9d-ef9b-95fb045ef1de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n"
     ]
    }
   ],
   "source": [
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "print(sorted(nltk_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhiCukC8JJgB",
    "outputId": "307f3582-40f0-4740-b8a0-817afbc970ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car wondering enlighten car saw day door sports car looked late s early s called bricklin doors small addition bumper separate rest body know tellme model engine specs years production car history info funky looking car e mail thanks\n"
     ]
    }
   ],
   "source": [
    "data=[remove_stopwords(sent) for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BETTEN17JJgC",
    "outputId": "3a7b05d2-bc00-4b19-b1b9-bacd8e732d47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car wondering enlighten car saw day door sports car looked late early called bricklin doors small addition bumper separate rest body know tellme model engine specs years production car history info funky looking car mail thanks\n"
     ]
    }
   ],
   "source": [
    "data=[strip_short(sent) for sent in data]\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9G64KrgJJgC"
   },
   "source": [
    "# 5. Stemming and Lematization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o7LTnx_uJJgC",
    "outputId": "44eea46e-1c6f-4014-eefa-74ce536ff57d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car wonder enlighten car saw dai door sport car look late earli call bricklin door small addit bumper separ rest bodi know tellm model engin spec year product car histori info funki look car mail thank\n"
     ]
    }
   ],
   "source": [
    "data_stem=[stem_text(sent) for sent in data]\n",
    "#data_stem=[strip_short(sent) for sent in data_stem]\n",
    "print(data_stem[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSLzKSPgJJgC",
    "outputId": "9db46f19-94a0-4552-f9e9-6da5e87695e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "car wonder enlighten car see day door sport car look late early call bricklin door small addition bumper separate rest body know tellme model engine specs year production car history info funky looking car mail thank\n"
     ]
    }
   ],
   "source": [
    "# Initialize spacy 'en' model\n",
    "nlp = en_core_web_sm.load()\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "data_lem_base=[nlp(sent) for sent in data]\n",
    "# Extract the lemma for each token and join\n",
    "data_lem=[\" \".join([token.lemma_ for token in sent]) for sent in data_lem_base]\n",
    "print(data_lem[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0yOdQK1bJJgD"
   },
   "source": [
    "# 6. Corpus storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n4F9ajJ0JJgD"
   },
   "source": [
    "IMPORTNANT: store your preprocessed corpus as you donâ€™t want to do this over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3BIVtHcgJJgD"
   },
   "outputs": [],
   "source": [
    "pickle.dump(data_stem, open(\"/content/drive/MyDrive/TWSM_Data/Stemmed.pkl\", \"wb\"))\n",
    "pickle.dump(data_lem, open(\"/content/drive/MyDrive/TWSM_Data/Lemma.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2_Text_Preprocessing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
